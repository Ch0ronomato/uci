{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ian Schweer</h3>\n",
    "<h3>22514022</h3>\n",
    "<h3>CS 177 - Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(C = 1) = 0.60617257118\n",
      "p(C = 2) = 0.394262116931\n",
      "P(X = 0 | C = 1 ) [1, 2] =  [0.85209752599498023, 0.14790247400501971]\n",
      "P(X = 1 | C = 1 ) [1, 2] =  [0.90193617784152025, 0.098063822158479738]\n",
      "P(X = 2 | C = 1 ) [1, 2] =  [0.72266045177482974, 0.27733954822517032]\n",
      "P(X = 3 | C = 1 ) [1, 2] =  [0.99695231265686624, 0.0030476873431337396]\n",
      "P(X = 4 | C = 1 ) [1, 2] =  [0.77967013266403729, 0.22032986733596271]\n",
      "P(X = 5 | C = 1 ) [1, 2] =  [0.88580136249551811, 0.11419863750448189]\n",
      "P(X = 6 | C = 1 ) [1, 2] =  [0.98440301183219792, 0.01559698816780208]\n",
      "P(X = 7 | C = 1 ) [1, 2] =  [0.92631767658659014, 0.073682323413409828]\n",
      "P(X = 8 | C = 1 ) [1, 2] =  [0.92165650770885621, 0.078343492291143776]\n",
      "P(X = 9 | C = 1 ) [1, 2] =  [0.8295087845105773, 0.17049121548942273]\n",
      "P(X = 10 | C = 1 ) [1, 2] =  [0.94890641807099319, 0.051093581929006815]\n",
      "P(X = 11 | C = 1 ) [1, 2] =  [0.5821082825385443, 0.4178917174614557]\n",
      "P(X = 12 | C = 1 ) [1, 2] =  [0.8807816421656508, 0.11921835783434923]\n",
      "P(X = 13 | C = 1 ) [1, 2] =  [0.95464324130512723, 0.045356758694872712]\n",
      "P(X = 14 | C = 1 ) [1, 2] =  [0.98225170311939758, 0.017748296880602366]\n",
      "P(X = 15 | C = 1 ) [1, 2] =  [0.90946575833632126, 0.090534241663678738]\n",
      "P(X = 16 | C = 1 ) [1, 2] =  [0.90444603800645396, 0.095553961993546072]\n",
      "P(X = 17 | C = 1 ) [1, 2] =  [0.8743277160272499, 0.1256722839727501]\n",
      "P(X = 18 | C = 1 ) [1, 2] =  [0.64126927214055218, 0.35873072785944782]\n",
      "P(X = 19 | C = 1 ) [1, 2] =  [0.98296880602366443, 0.017031193976335603]\n",
      "P(X = 20 | C = 1 ) [1, 2] =  [0.69325923269989242, 0.30674076730010758]\n",
      "P(X = 21 | C = 1 ) [1, 2] =  [0.99193259232699893, 0.0080674076730010754]\n",
      "P(X = 22 | C = 1 ) [1, 2] =  [0.97221226245966297, 0.027787737540337039]\n",
      "P(X = 23 | C = 1 ) [1, 2] =  [0.98045894585873072, 0.019541054141269273]\n",
      "P(X = 24 | C = 1 ) [1, 2] =  [0.6269272140552169, 0.3730727859447831]\n",
      "P(X = 25 | C = 1 ) [1, 2] =  [0.71871638580136255, 0.28128361419863751]\n",
      "P(X = 26 | C = 1 ) [1, 2] =  [0.72301900322696311, 0.27698099677303695]\n",
      "P(X = 27 | C = 1 ) [1, 2] =  [0.84456794550017933, 0.15543205449982073]\n",
      "P(X = 28 | C = 1 ) [1, 2] =  [0.87074220150591608, 0.12925779849408389]\n",
      "P(X = 29 | C = 1 ) [1, 2] =  [0.83811401936177843, 0.16188598063822157]\n",
      "P(X = 30 | C = 1 ) [1, 2] =  [0.89584080315525283, 0.10415919684474723]\n",
      "P(X = 31 | C = 1 ) [1, 2] =  [0.92703477949085689, 0.072965220509143058]\n",
      "P(X = 32 | C = 1 ) [1, 2] =  [0.87647902474005024, 0.1235209752599498]\n",
      "P(X = 33 | C = 1 ) [1, 2] =  [0.92631767658659014, 0.073682323413409828]\n",
      "P(X = 34 | C = 1 ) [1, 2] =  [0.84241663678737899, 0.15758336321262101]\n",
      "P(X = 35 | C = 1 ) [1, 2] =  [0.82520616708497674, 0.17479383291502332]\n",
      "P(X = 36 | C = 1 ) [1, 2] =  [0.73879526712083188, 0.26120473287916818]\n",
      "P(X = 37 | C = 1 ) [1, 2] =  [0.98153460021513084, 0.018465399784869128]\n",
      "P(X = 38 | C = 1 ) [1, 2] =  [0.88436715668698462, 0.11563284331301542]\n",
      "P(X = 39 | C = 1 ) [1, 2] =  [0.90982430978845463, 0.090175690211545353]\n",
      "P(X = 40 | C = 1 ) [1, 2] =  [0.94711366081032633, 0.052886339189673719]\n",
      "P(X = 41 | C = 1 ) [1, 2] =  [0.88472570813911799, 0.11527429186088203]\n",
      "P(X = 42 | C = 1 ) [1, 2] =  [0.89584080315525283, 0.10415919684474723]\n",
      "P(X = 43 | C = 1 ) [1, 2] =  [0.89942631767658654, 0.1005736823234134]\n",
      "P(X = 44 | C = 1 ) [1, 2] =  [0.70437432771602726, 0.29562567228397274]\n",
      "P(X = 45 | C = 1 ) [1, 2] =  [0.83883112226604517, 0.16116887773395483]\n",
      "P(X = 46 | C = 1 ) [1, 2] =  [0.98404446038006455, 0.015955539619935462]\n",
      "P(X = 47 | C = 1 ) [1, 2] =  [0.93277160272499104, 0.067228397275008969]\n",
      "P(X = 48 | C = 1 ) [1, 2] =  [0.81373252061670853, 0.1862674793832915]\n",
      "P(X = 49 | C = 1 ) [1, 2] =  [0.50143420580853348, 0.49856579419146646]\n",
      "P(X = 50 | C = 1 ) [1, 2] =  [0.85675869487271428, 0.14324130512728578]\n",
      "P(X = 51 | C = 1 ) [1, 2] =  [0.73198278953029761, 0.26801721046970239]\n",
      "P(X = 52 | C = 1 ) [1, 2] =  [0.89548225170311935, 0.1045177482968806]\n",
      "P(X = 53 | C = 1 ) [1, 2] =  [0.91771244173538902, 0.082287558264610969]\n",
      "P(X = 54 | C = 1 ) [1, 2] =  [0.66959483685908927, 0.33040516314091073]\n",
      "P(X = 55 | C = 1 ) [1, 2] =  [0.70437432771602726, 0.29562567228397274]\n",
      "P(X = 56 | C = 1 ) [1, 2] =  [0.65740408748655432, 0.34259591251344568]\n",
      "P(X = 0 | C = 2 ) [1, 2] =  [0.64636163175303196, 0.35363836824696804]\n",
      "P(X = 1 | C = 2 ) [1, 2] =  [0.65518191841234841, 0.34481808158765159]\n",
      "P(X = 2 | C = 2 ) [1, 2] =  [0.38506063947078278, 0.61493936052921716]\n",
      "P(X = 3 | C = 2 ) [1, 2] =  [0.97822491730981254, 0.021775082690187433]\n",
      "P(X = 4 | C = 2 ) [1, 2] =  [0.37458654906284455, 0.6254134509371555]\n",
      "P(X = 5 | C = 2 ) [1, 2] =  [0.6243109151047409, 0.3756890848952591]\n",
      "P(X = 6 | C = 2 ) [1, 2] =  [0.57855567805953689, 0.42144432194046305]\n",
      "P(X = 7 | C = 2 ) [1, 2] =  [0.65848952590959209, 0.34151047409040791]\n",
      "P(X = 8 | C = 2 ) [1, 2] =  [0.69377067254685776, 0.30622932745314224]\n",
      "P(X = 9 | C = 2 ) [1, 2] =  [0.54382579933847852, 0.45617420066152148]\n",
      "P(X = 10 | C = 2 ) [1, 2] =  [0.6871554575523704, 0.31284454244762955]\n",
      "P(X = 11 | C = 2 ) [1, 2] =  [0.37458654906284455, 0.6254134509371555]\n",
      "P(X = 12 | C = 2 ) [1, 2] =  [0.71306504961411243, 0.28693495038588757]\n",
      "P(X = 13 | C = 2 ) [1, 2] =  [0.87238147739801541, 0.12761852260198456]\n",
      "P(X = 14 | C = 2 ) [1, 2] =  [0.84151047409040791, 0.15848952590959206]\n",
      "P(X = 15 | C = 2 ) [1, 2] =  [0.45452039691289969, 0.54547960308710031]\n",
      "P(X = 16 | C = 2 ) [1, 2] =  [0.61549062844542446, 0.38450937155457554]\n",
      "P(X = 17 | C = 2 ) [1, 2] =  [0.62045203969128992, 0.37954796030871002]\n",
      "P(X = 18 | C = 2 ) [1, 2] =  [0.29796030871003309, 0.70203969128996691]\n",
      "P(X = 19 | C = 2 ) [1, 2] =  [0.79189636163175303, 0.20810363836824697]\n",
      "P(X = 20 | C = 2 ) [1, 2] =  [0.20424476295479604, 0.79575523704520401]\n",
      "P(X = 21 | C = 2 ) [1, 2] =  [0.94735391400220503, 0.052646085997794925]\n",
      "P(X = 22 | C = 2 ) [1, 2] =  [0.66786108048511572, 0.33213891951488422]\n",
      "P(X = 23 | C = 2 ) [1, 2] =  [0.6243109151047409, 0.3756890848952591]\n",
      "P(X = 24 | C = 2 ) [1, 2] =  [0.97216097023153247, 0.027839029768467475]\n",
      "P(X = 25 | C = 2 ) [1, 2] =  [0.9848401323042999, 0.015159867695700111]\n",
      "P(X = 26 | C = 2 ) [1, 2] =  [0.99531422271223813, 0.004685777287761852]\n",
      "P(X = 27 | C = 2 ) [1, 2] =  [0.98318632855567811, 0.016813671444321939]\n",
      "P(X = 28 | C = 2 ) [1, 2] =  [0.99310915104740904, 0.006890848952590959]\n",
      "P(X = 29 | C = 2 ) [1, 2] =  [0.98980154355016536, 0.010198456449834619]\n",
      "P(X = 30 | C = 2 ) [1, 2] =  [0.99807056229327451, 0.0019294377067254685]\n",
      "P(X = 31 | C = 2 ) [1, 2] =  [0.99862183020948181, 0.0013781697905181918]\n",
      "P(X = 32 | C = 2 ) [1, 2] =  [0.96609702315325252, 0.033902976846747521]\n",
      "P(X = 33 | C = 2 ) [1, 2] =  [0.99421168687982364, 0.0057883131201764059]\n",
      "P(X = 34 | C = 2 ) [1, 2] =  [0.97436604189636167, 0.025633958103638367]\n",
      "P(X = 35 | C = 2 ) [1, 2] =  [0.9379823594266814, 0.062017640573318635]\n",
      "P(X = 36 | C = 2 ) [1, 2] =  [0.94404630650496146, 0.055953693495038585]\n",
      "P(X = 37 | C = 2 ) [1, 2] =  [0.98208379272326352, 0.017916207276736495]\n",
      "P(X = 38 | C = 2 ) [1, 2] =  [0.96554575523704522, 0.034454244762954798]\n",
      "P(X = 39 | C = 2 ) [1, 2] =  [0.88836824696802641, 0.11163175303197354]\n",
      "P(X = 40 | C = 2 ) [1, 2] =  [0.99917309812568911, 0.00082690187431091512]\n",
      "P(X = 41 | C = 2 ) [1, 2] =  [0.98869900771775088, 0.011300992282249173]\n",
      "P(X = 42 | C = 2 ) [1, 2] =  [0.9528665931642778, 0.047133406835722161]\n",
      "P(X = 43 | C = 2 ) [1, 2] =  [0.97381477398015437, 0.026185226019845645]\n",
      "P(X = 44 | C = 2 ) [1, 2] =  [0.73125689084895262, 0.26874310915104743]\n",
      "P(X = 45 | C = 2 ) [1, 2] =  [0.96223814773980154, 0.037761852260198459]\n",
      "P(X = 46 | C = 2 ) [1, 2] =  [0.98925027563395806, 0.010749724366041897]\n",
      "P(X = 47 | C = 2 ) [1, 2] =  [0.99090407938257996, 0.0090959206174200669]\n",
      "P(X = 48 | C = 2 ) [1, 2] =  [0.85033076074972436, 0.14966923925027564]\n",
      "P(X = 49 | C = 2 ) [1, 2] =  [0.50303197353913998, 0.49696802646085997]\n",
      "P(X = 50 | C = 2 ) [1, 2] =  [0.92805953693495036, 0.071940463065049615]\n",
      "P(X = 51 | C = 2 ) [1, 2] =  [0.16675854465270121, 0.83324145534729877]\n",
      "P(X = 52 | C = 2 ) [1, 2] =  [0.38836824696802646, 0.61163175303197359]\n",
      "P(X = 53 | C = 2 ) [1, 2] =  [0.71251378169790514, 0.28748621830209481]\n",
      "P(X = 54 | C = 2 ) [1, 2] =  [0.24007717750826901, 0.75992282249173093]\n",
      "P(X = 55 | C = 2 ) [1, 2] =  [0.25275633958103638, 0.74724366041896362]\n",
      "P(X = 56 | C = 2 ) [1, 2] =  [0.26488423373759645, 0.73511576626240349]\n",
      "0.10899709771\n",
      "0.128345694937\n",
      "0.192841019026\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class params:\n",
    "\t_targets = []\n",
    "\t_data = []\n",
    "\t_classes = []\n",
    "\t_classProbs = []\n",
    "\tdef __init__(self, Data, Classes, Targets):\n",
    "\t\tself._targets = np.array(Targets)\n",
    "\t\tself._data = np.array(Data)\n",
    "\t\tself._classes = np.array(Classes)\n",
    "\t\tself._classProbs = np.array([self.lenfrac(Data[Targets==Classes[0]]) + 1, self.lenfrac(Data[Targets==Classes[1]]) + 1])\n",
    "\n",
    "\t# get frame \n",
    "\tdef lenfrac(self, var):\n",
    "\t\treturn 1. * len(var)\n",
    "\tdef params(self, j, i):\n",
    "\t\tif (j < 0 or j >= self._data.shape[1]):\n",
    "\t\t\traise Exception(\"j out of bounds\",j)\n",
    "\t\treturn self._data[self._targets == i, j]\n",
    "\n",
    "\tdef mprobs(self, j, k, i):\n",
    "\t\tvar = self.params(j, i);\n",
    "\t\treturn var[var == k]\n",
    "\n",
    "\tdef getclass(self, c):\n",
    "\t\treturn self._classProbs[self._classes==c][0]\n",
    "\n",
    "\tdef classprobs(self, c):\n",
    "\t\treturn self.getclass(c) / len(self._data)\n",
    "\n",
    "\tdef pofx(self, x):\n",
    "\t\t# given a vector of x values\n",
    "\t\t# compute the probability of the value\n",
    "\t\t# then multiply them all together.\n",
    "\t\tpx = 1.0\n",
    "\t\tfor i, xj in enumerate(x):\n",
    "\t\t\tX = self._data[:,i]\n",
    "\t\t\tcounter = 0\n",
    "\t\t\tfor y in X:\n",
    "\t\t\t\tcounter = counter + (y == xj)\n",
    "\t\t\tpx = (counter / self.lenfrac(X))\n",
    "\t\treturn px\n",
    "\n",
    "\tdef cprobs(self, j, k, i):\n",
    "\t\tdenom = self.getclass(i)\n",
    "\t\thead = self.lenfrac(self.mprobs(j,k,i))\n",
    "\t\t# naive bayes assumes conditional independence. So P[X|Y] = P(X)P(Y)\n",
    "\t\treturn (head + .5) / self.getclass(i)\n",
    "\n",
    "X = np.genfromtxt('data.txt')\n",
    "Y = np.genfromtxt('labels.txt')\n",
    "\n",
    "classes=[1,2]\n",
    "p = params(X, classes, Y)\n",
    "print \"p(C = 1) =\",p.getclass(classes[0]) / len(X)\n",
    "print \"p(C = 2) =\",p.getclass(classes[1]) / len(X)\n",
    "\n",
    "for c in classes:\n",
    "\tfor i in range(0,X.shape[1]): \n",
    "\t\tps = [p.cprobs(i, 1, c), p.cprobs(i, 2, c)]\n",
    "\t\tprint \"P(X =\",i,\"| C =\",c,\") [1, 2] = \", ps\n",
    "\n",
    "#train using only a subset of data.\n",
    "Xte,Yte = X[1500:], Y[1500:]\n",
    "predictions = np.array([])\n",
    "for i in [1500, 50, 10]:\n",
    "\tXtr,Ytr = (X[0:i], Y[0:i])\n",
    "\tp = params(Xtr, classes, Ytr)\n",
    "\tfor d in range(Xte.shape[0]):\n",
    "\t\tpxji = np.empty(2) # P(Xj|C=i)\n",
    "\t\tpxji.fill(1.0)\n",
    "\t\tfor ci,c in enumerate(classes):\n",
    "\t\t\ttemp = 1.0\n",
    "\t\t\tfor ji,j in enumerate(Xte[d]):\n",
    "\t\t\t\ttemp = temp * p.cprobs(ji, j, c)\n",
    "\t\t\tpxji[ci] = temp * p.classprobs(c)\n",
    "\t\tpredictions=np.append(predictions, classes[pxji.argmax()])\n",
    "\tprint np.mean(predictions.reshape(Yte.shape) != Yte)\n",
    "\tpredictions = np.array([])\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How does the accuracy vary across experiements?</b>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>Our error rate <p style=\"display:inline;font-weight:bold\">increases</p>. This is because our naive bayes classifer can only use data it has seen too determine it's prediction. As we lower the amount of data feed into the classifer, the less information it has to determine the output of a feature vector is hasn't seen before.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Suppose a classifier randomly guessed the class labels with equal probabilities of 0.5. How accurate would you expect it to be?</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>For this classifier, P(C=i | Xj) = .5, which means we would need a way to choose the class C. Assume that C is binary [Spam, Not Spam], and we always pick a class based off some random method (e.g. random number generator). That means at best, ever item in our dataset happens to be class as our guess, giving us 0% error. That is unlikely. It's also unlikely that we get every single item wrong. Given that, I would assume this classifier would get about <p style=\"font-weight:bold;display:inline;\">50% incorrect</p>, with a 10% fluctuation on each side, depending on the \"luck\" of our random number generator.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How accurate would a classifier be that always predicted the class label which occurred most commonly in the training set (i.e., if the majority of examples 1â€“1500 were class i, it would always report class i regardless of input)?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>This classifer could predict as well as the previous classifer, with about a 50% error. However, this classifer is susceptible to bad sampling. An example, what if only 33% of our data is class 1 and that happens to be our training data? Then we would 100% on the testing set, and probably 50% error on the remaining. If this was a rather representative sample, then we would have an error close to ratio of the minority element in the dataset. On average, I suspect this classifer to get roughly <p style=\"font-weight:bold;display:inline;\">50%</p> incorrect.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How do these two simple strategies compare to the performance of your system measured in parts 1-3?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>This two classifers are definietly easier to implement then the one I built. However, they would do really bad in practice. The reason for this is neither classifer learns from our dataset. Our classifer attempts to understand the class labeling from a cooresponding feature vector.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Write a third function which returns the probability of the class label C being spam and non-spam. Compute these probabilities for the first 20 examples in the data file. You do not have to turn in code for this function, just the table of values. You will probably want to use the code you have already written for nbayes predict.m as a template and modify it slightly to return the class probabilities rather than just the most likely class.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.41543637e-13   1.51357769e-07]\n",
      "[  1.17329313e-08   3.75416247e-13]\n",
      "[  9.95858565e-09   2.48213923e-08]\n",
      "[  5.03947933e-14   1.57412080e-08]\n",
      "[  3.55752516e-08   8.49358025e-15]\n",
      "[  8.20289353e-08   1.79510398e-10]\n",
      "[  2.41290270e-12   6.31817258e-10]\n",
      "[  6.50762886e-07   2.19680557e-10]\n",
      "[  6.04516570e-19   2.48213923e-08]\n",
      "[  4.34270834e-08   3.35982028e-11]\n",
      "[  2.44451735e-18   9.20677170e-29]\n",
      "[  2.91144988e-12   2.90042214e-26]\n",
      "[  3.20521467e-14   2.03283244e-14]\n",
      "[  5.06840779e-14   5.38748322e-26]\n",
      "[  2.07990511e-10   2.24627985e-11]\n",
      "[  2.60305155e-08   2.19680557e-10]\n",
      "[  3.44521528e-07   1.29223857e-11]\n",
      "[  6.84459274e-28   2.99085093e-14]\n",
      "[  2.86841849e-10   1.87708124e-12]\n",
      "[  3.62629200e-17   1.81342137e-09]\n"
     ]
    }
   ],
   "source": [
    "Xte,Yte = X[20:], Y[20:]\n",
    "predictions = np.array([])\n",
    "for i in [20]:\n",
    "\tXtr,Ytr = (X[0:i], Y[0:i])\n",
    "\tp = params(Xtr, classes, Ytr)\n",
    "\tfor d in range(Xtr.shape[0]):\n",
    "\t\tpxji = np.empty(2) # P(Xj|C=i)\n",
    "\t\tpxji.fill(1.0)\n",
    "\t\tfor ci,c in enumerate(classes):\n",
    "\t\t\ttemp = 1.0\n",
    "\t\t\tfor ji,j in enumerate(Xtr[d]):\n",
    "\t\t\t\ttemp = temp * p.cprobs(ji, j, c)\n",
    "\t\t\tpxji[ci] = (temp * p.classprobs(c)) / p.pofx(Xtr[d])\n",
    "\t\tprint pxji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
